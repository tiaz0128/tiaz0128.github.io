---
layout: post
date: 2025-02-11
upd_date: 2025-02-11
catalogue: "Celery"
subject: "Celery"
title: "Celery 동시 처리"
description: "Celery를 통한 여러 작업을 한번에 처리하는 방법"
author: tiaz0128
permalink: /Celery/2
tags: [Celery]
prev_post: /Celery/1
# next_post: /Celery/3
---



동시에 처리

순서대로 처리

MQ에 여러개 처리

이전 글의 덧셈 예제를 확장하여 대량의 계산 작업 처리
코드 예시:

작업 생성 시 여러 개의 task를 group()으로 묶어서 처리
chord()를 사용하여 여러 작업의 결과를 집계
작업 우선순위 설정

---

Celery의 동시성 처리 방식 소개

Worker Pool 개념 설명 (prefork/gevent/eventlet)
Concurrency 옵션 설명
Task Priority 설정 방법

네, 이해했습니다. Celery에서 덧셈과 곱셈의 순서가 중요한 작업을 예시로 들어 동시 처리의 문제점과 순차 처리의 필요성을 설명하는 글을 작성해보겠습니다.

1. **블로그 글의 흐름**

```markdown
## 작업 순서가 중요하다면?

이전 글에서는 단순히 두 수를 더하는 작업을 처리했습니다. 하지만 실제 환경에서는 작업 간의 순서가 중요한 경우가 많습니다. 
예를 들어 A + B의 결과에 C를 곱해야 하는 상황을 생각해봅시다.

## 동시 처리의 문제점

아래와 같이 덧셈과 곱셈 작업을 각각 다른 큐로 분리하여 동시에 처리하면 어떻게 될까요?

[동시 처리 도식화 이미지]

예상과 다른 결과가 나올 수 있습니다. 곱셈 작업이 덧셈 작업보다 먼저 실행될 수 있기 때문입니다.
```

2. **예제 코드**

먼저 두 개의 작업을 정의합니다:

```python
# tasks/math.py
from celery import chain
from run import app

@app.task(queue="add-queue")
def add(x, y):
    result = x + y
    print(f"Adding {x} + {y} = {result}")
    return result

@app.task(queue="multiply-queue")
def multiply(x, y):
    result = x * y
    print(f"Multiplying {x} * {y} = {result}")
    return result
```

동시 처리 시의 문제점을 보여주는 FastAPI 엔드포인트:

```python
# apps/rest-api/run.py
@app.get("/parallel")
def parallel_operation():
    celery = Celery(
        "Math Operations",
        broker=f"pyamqp://{username}:{password}@{url}//"
    )
    
    # 동시에 실행되어 순서가 보장되지 않음
    add_task = celery.send_task(
        "tasks.math.add",
        kwargs={"x": 10, "y": 20},
        queue="add-queue"
    )
    
    multiply_task = celery.send_task(
        "tasks.math.multiply",
        kwargs={"x": add_task.id, "y": 3},  # 의존성이 있지만 동시 실행됨
        queue="multiply-queue"
    )
    
    return PlainTextResponse("Tasks sent to queues")
```

3. **순차 처리로 해결하기**

Celery의 `chain`을 사용한 순차 처리:

```python
@app.get("/sequential")
def sequential_operation():
    celery = Celery(
        "Math Operations",
        broker=f"pyamqp://{username}:{password}@{url}//"
    )
    
    # chain을 사용하여 작업 순서 보장
    workflow = chain(
        add.s(10, 20),
        multiply.s(3)
    )
    
    result = workflow.apply_async()
    return PlainTextResponse("Sequential tasks started")
```

4. **Celery의 동시성 처리 방식** 

Celery는 다음과 같은 동시성 처리 패턴을 제공합니다:

```python
from celery import group, chain, chord

# 병렬 실행: 여러 작업을 동시에 실행
parallel_tasks = group([
    add.s(2, 2),
    add.s(4, 4),
    add.s(8, 8)
])

# 순차 실행: 작업을 순서대로 실행
sequential_tasks = chain(
    add.s(2, 2),
    multiply.s(3),
    add.s(5)
)

# 병렬 실행 후 콜백: 여러 작업을 동시에 실행하고 결과를 집계
callback_tasks = chord(
    group([add.s(i, i) for i in range(10)]),
    sum_results.s()
)
```

5. **작업 우선순위와 큐 설정**

```python
@app.task(queue="high-priority")
def critical_task():
    pass

# Worker 실행 시 큐 우선순위 설정
# celery -A tasks worker -Q high-priority,default
```

이러한 구조로 글을 작성하면, 동시 처리의 문제점과 순차 처리의 필요성을 잘 설명할 수 있을 것 같습니다. 실제 예제를 통해 문제 상황을 보여주고, Celery의 다양한 처리 방식을 소개하면서 해결책을 제시하는 흐름으로 구성하면 좋을 것 같습니다.

Celery에서 작업 우선순위와 큐 설정에 대해 자세히 설명해드리겠습니다.

1. **큐(Queue) 우선순위 설정**

```python
# celeryconfig.py
task_queues = {
    'high': {
        'exchange': 'high',
        'routing_key': 'high.priority',
    },
    'normal': {
        'exchange': 'normal',
        'routing_key': 'normal.priority',
    },
    'low': {
        'exchange': 'low',
        'routing_key': 'low.priority',
    }
}

task_routes = {
    'tasks.critical_task': {'queue': 'high'},
    'tasks.normal_task': {'queue': 'normal'},
    'tasks.batch_task': {'queue': 'low'},
}
```

2. **작업 정의 시 큐 지정**

```python
# tasks/priority_tasks.py
from celery import Task

class HighPriorityTask(Task):
    queue = 'high'
    
@app.task(base=HighPriorityTask)
def critical_task():
    pass

# 또는 데코레이터에서 직접 지정
@app.task(queue='high')
def another_critical_task():
    pass
```

3. **Worker 실행 시 큐 우선순위 지정**

```bash
# 우선순위 순서대로 큐 지정
celery -A tasks worker -Q high,normal,low

# 특정 큐만 처리하는 워커 실행
celery -A tasks worker -Q high --hostname=high_priority@%h
celery -A tasks worker -Q normal,low --hostname=normal_worker@%h
```

4. **작업 실행 시 큐 지정**

```python
# 작업 실행 시 큐 지정
@app.get("/task")
def create_task():
    # 기본 큐 대신 high 큐로 전송
    result = critical_task.apply_async(
        args=[],
        queue='high'
    )
    
    # 우선순위와 함께 전송
    result = normal_task.apply_async(
        args=[],
        priority=5  # 우선순위 설정 (0-9, 높을수록 우선)
    )
```

5. **큐 모니터링**

```python
# Flower를 사용한 큐 모니터링
celery -A tasks flower --port=5555

# 또는 RabbitMQ 관리자 콘솔에서 확인
# http://localhost:15672
```

6. **실제 운영 시 고려사항**

```python
# 큐별 동시성 제한 설정
app.conf.task_annotations = {
    'tasks.critical_task': {'rate_limit': '10/s'},
    'tasks.normal_task': {'rate_limit': '1000/h'},
}

# 타임아웃 설정
@app.task(queue='high', soft_time_limit=60, time_limit=120)
def time_sensitive_task():
    pass
```

7. **에러 처리와 재시도 설정**

```python
@app.task(
    queue='high',
    autoretry_for=(Exception,),
    retry_kwargs={'max_retries': 5},
    retry_backoff=True,
    retry_backoff_max=600
)
def reliable_task():
    pass
```

이러한 설정들을 통해:
- 중요한 작업은 높은 우선순위 큐에서 처리
- 백그라운드 작업은 낮은 우선순위 큐에서 처리
- 워커를 큐별로 분리하여 리소스 관리
- 작업별 처리 속도와 재시도 정책 제어

가 가능합니다. 실제 운영 환경에서는 이러한 설정들을 조합하여 최적의 성능과 안정성을 확보할 수 있습니다.


RabbitMQ의 Exchange와 Routing Key는 메시지가 어떻게 큐로 전달되는지를 결정하는 중요한 개념입니다. 이를 자세히 설명해드리겠습니다:

## Exchange와 Routing Key의 기본 개념

```
[Producer] --> [Exchange] --> (routing) --> [Queue] --> [Consumer]
```

1. **Exchange**
   - 메시지를 받아서 큐로 전달하는 라우터 역할
   - Producer는 메시지를 직접 큐에 전달하지 않고, Exchange에 전달
   - Exchange가 routing_key를 기반으로 적절한 큐에 메시지를 전달
   - Producer는 메시지를 어떤 큐에 전달할지 직접 알 필요가 없음
   - Exchange 설정만 변경하면 메시지 흐름을 쉽게 변경 가능
   - 하나의 메시지를 여러 큐에 동시에 전달 가능

2. **Routing Key**
   - 메시지가 어떤 큐로 전달될지 결정하는 주소 역할
   - Exchange type에 따라 routing_key의 사용 방식이 다름

## Exchange Types

1. **Direct Exchange**
```python
task_queues = {
    'high': {
        'exchange': 'high',
        'routing_key': 'high.priority',  # 정확히 일치하는 routing_key를 가진 큐로 전달
    }
}
```

2. **Topic Exchange**
```python
task_queues = {
    'high': {
        'exchange': 'tasks',
        'routing_key': 'priority.high.*'  # 패턴 매칭을 사용
    }
}
```

3. **Fanout Exchange**
```python
task_queues = {
    'high': {
        'exchange': 'broadcast',
        'routing_key': ''  # routing_key 무시, 모든 큐에 전달
    }
}
```

## 실제 사용 예시

```python
# Celery 설정
task_queues = {
    'high': {
        'exchange': 'tasks',
        'routing_key': 'priority.high'
    },
    'normal': {
        'exchange': 'tasks',
        'routing_key': 'priority.normal'
    }
}

# 작업 정의
@app.task(
    exchange='tasks',
    routing_key='priority.high'
)
def high_priority_task():
    pass

# 작업 실행
high_priority_task.apply_async(
    args=[],
    exchange='tasks',
    routing_key='priority.high'
)
```

## 장점

1. **유연한 라우팅**
   - 하나의 메시지를 여러 큐에 전달 가능
   - 동적으로 라우팅 규칙 변경 가능

2. **높은 확장성**
   - Exchange와 Queue를 분리하여 시스템 구조 변경 용이
   - 새로운 큐 추가가 기존 시스템에 영향을 주지 않음

3. **메시지 필터링**
   - routing_key를 통해 메시지를 필터링하여 전달
   - 불필요한 메시지 처리 방지

이러한 구조를 통해 복잡한 메시징 시나리오를 유연하게 처리할 수 있습니다.

Exchange가 필요한 중요한 이유들을 설명드리겠습니다:

1. **메시지 라우팅의 유연성**
```
[직접 큐 전달 방식]
Producer -> Queue1
Producer -> Queue2
Producer -> Queue3

[Exchange 사용 방식]
Producer -> Exchange -> Queue1
                    -> Queue2
                    -> Queue3
```
- Producer는 메시지를 어떤 큐에 전달할지 직접 알 필요가 없음
- Exchange 설정만 변경하면 메시지 흐름을 쉽게 변경 가능
- 하나의 메시지를 여러 큐에 동시에 전달 가능

2. **시스템 결합도 감소**
```python
# Exchange 없이 직접 큐 지정
task.apply_async(queue='specific_queue')

# Exchange 사용
task.apply_async(
    exchange='task_exchange',
    routing_key='high.priority'
)
```
- Producer와 Queue 사이의 직접적인 의존성 제거
- 큐 구조가 변경되어도 Producer 코드 수정 불필요
- 시스템 유지보수와 확장이 용이

3. **메시지 패턴 매칭**
```python
# Topic Exchange 예시
task_queues = {
    'image.resize.*': queue1,  # 이미지 리사이즈 관련 모든 작업
    'image.*.high': queue2,    # 이미지 관련 높은 우선순위 작업
    'image.*.low': queue3      # 이미지 관련 낮은 우선순위 작업
}
```
- 복잡한 라우팅 규칙을 패턴으로 정의 가능
- 동적인 메시지 라우팅 구현 가능

4. **부하 분산과 고가용성**
```
Producer -> Exchange -> [Queue1, Queue2, Queue3]
```
- 메시지를 여러 큐에 분산하여 처리 가능
- 특정 큐에 문제가 생겨도 다른 큐로 우회 가능

5. **메시지 브로드캐스팅**
```python
# Fanout Exchange 예시
task.apply_async(
    exchange='broadcast_exchange',
    exchange_type='fanout'
)
```
- 하나의 메시지를 모든 큐에 동시에 전달 가능
- 이벤트 기반 아키텍처 구현에 유용

즉, Exchange는 단순한 중간 계층이 아니라 메시지 라우팅의 유연성, 시스템 확장성, 고가용성을 제공하는 중요한 컴포넌트입니다. 직접 큐에 메시지를 전달할 수도 있지만, 그렇게 되면 위와 같은 이점들을 활용할 수 없게 됩니다.